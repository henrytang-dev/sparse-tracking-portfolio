{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Params #  \n",
        "X -> m-by-n matrix of net returns (samples-by-assets)  \n",
        "r -> m-dimensional vec of net returns of index  \n",
        "reg -> sparsity regularization parameter  \n",
        "u -> upper bound of weights  \n",
        "w_0 -> initial point  \n",
        "p_neg_exp -> final negative exponent of p  \n",
        "max_iter -> max number of iterations  \n",
        "\n",
        "return n-dimensional vector w/ allocation weights on the assets  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Add support for other indices besides S&P (maybe just simple if-else switches)\n",
        "# TODO: may need to build out a backtest framework that will yield results over longer periods of time\n",
        "# TODO: Add comments to optimization algorithm along with mathematical formulation (Henry)\n",
        "# TODO: Fix bugs on tracking algorithm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjzoxVJs7btS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from sec import stock, constants, lookups\n",
        "from polygon import RESTClient\n",
        "import yfinance as yf # temporary until we figure out polygon api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "constants.set_polygon_key(\"_4BtZn3PRCLu6fsdu7dgddb4ucmB1sfp\")\n",
        "poly_cli = RESTClient(api_key=\"_4BtZn3PRCLu6fsdu7dgddb4ucmB1sfp\")\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "curr_sp = lookups.get_sp500_tickers()\n",
        "print(len(curr_sp))\n",
        "print(curr_sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aggregate all close data (has been modularized below)\n",
        "# TODO: remove later after backtesting\n",
        "close_data = torch.zeros((252, len(curr_sp)))\n",
        "\n",
        "for i in range(len(curr_sp)):\n",
        "    aggs = []\n",
        "    data = poly_cli.list_aggs(ticker=curr_sp[i], multiplier=1, timespan=\"day\", from_=\"2023-02-01\", to = \"2024-02-01\")\n",
        "    for j, agg in enumerate(data):\n",
        "        close_data[j, i] = agg.close\n",
        "\n",
        "print(close_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "col_dim = close_data.shape[0]\n",
        "return_data = torch.zeros((252, len(curr_sp)))\n",
        "for i in range(1, col_dim):\n",
        "    return_data[i] = (close_data[i, :] - close_data[0, :])/close_data[0, :]\n",
        "print(return_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getCloseData():\n",
        "    curr_sp = lookups.get_sp500_tickers()\n",
        "    close_data = torch.zeros((252, len(curr_sp)))\n",
        "\n",
        "    for i in range(len(curr_sp)):\n",
        "        # aggs = []\n",
        "        data = poly_cli.list_aggs(ticker=curr_sp[i], multiplier=1, timespan=\"day\", from_=\"2023-02-01\", to = \"2024-02-01\")\n",
        "        for j, agg in enumerate(data):\n",
        "            close_data[j, i] = agg.close\n",
        "    return close_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# curr_sp is current s&p tickers\n",
        "# method simply retrieves close of certain ticker we specify\n",
        "def getTickerClose(ticker, curr_sp, close_data):\n",
        "    ix = curr_sp.index(ticker)\n",
        "    print(close_data[:, ix])\n",
        "\n",
        "# getTickerClose(\"AAPL\", curr_sp, close_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculateTickerReturns():\n",
        "    col_dim = close_data.shape[0]\n",
        "    return_data = torch.zeros((252, len(curr_sp)))\n",
        "    for i in range(1, col_dim):\n",
        "        return_data[i] = (close_data[i, :] - close_data[0, :])/close_data[0, :]\n",
        "    return return_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collectSP500():\n",
        "    index_symbol = \"^GSPC\"\n",
        "    index_data = yf.download(index_symbol, period=\"1y\", interval=\"1d\")\n",
        "    index_close_data = torch.tensor(index_data[\"Close\"].values)\n",
        "    return index_close_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculateIndexReturns():\n",
        "    index_data = collectSP500()\n",
        "    dim = index_data.shape[0]\n",
        "    return_data = torch.zeros(252)\n",
        "    for i in range(1, dim):\n",
        "        return_data[i] = ((index_data[i] - index_data[0])) / index_data[0]\n",
        "    return return_data.reshape(252, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: currently subscription doesnt have access to index data; will come back\n",
        "# aggs = []\n",
        "# for a in poly_cli.list_aggs(\"I:SPX\", 1, \"day\", \"2023-03-10\", \"2023-05-12\", limit=50000):\n",
        "#     aggs.append(a)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Algorithm #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwnN40TU76Hy"
      },
      "outputs": [],
      "source": [
        "# funcition to solve kkt\n",
        "def bisection(c, u):\n",
        "  n = len(c)\n",
        "  w = torch.zeros(n) # new weight vector\n",
        "  c_sort, sort_indices = torch.sort(c)\n",
        "  \n",
        "  high = n - 1\n",
        "  low = 0\n",
        "\n",
        "  while low <= high:\n",
        "    mid = (low + high) // 2\n",
        "    if mid == 0:\n",
        "      break\n",
        "    mu = -1/mid * (torch.sum(c_sort[0:mid]) + 2)\n",
        "\n",
        "    cond1 = (mu + c_sort[mid] < 0).item()\n",
        "\n",
        "    if mid < n:\n",
        "      cond2 = torch.all((mu + c_sort[mid] >= 0)).item()\n",
        "    else:\n",
        "      cond2 = True\n",
        "\n",
        "    if cond1 and cond2:\n",
        "      break\n",
        "    elif cond1 and not cond2:\n",
        "      low = mid + 1\n",
        "    else:\n",
        "      high = mid - 1\n",
        "\n",
        "  new_values = -(mu + c_sort[:mid] / 2)\n",
        "  if torch.all(-(mu + c_sort[:mid])/2 <= u).item():\n",
        "      # print(f\"This is w.shape in bisection: {w.shape}\")\n",
        "      # print(f\"This is what is getting put in w in bisecttion: {(-(mu + c_sort[:mid])/2).shape}\")\n",
        "      w[sort_indices[:mid]] = -(mu + c_sort[:mid])/2\n",
        "      # print(\"We get to the if and this is executed\")\n",
        "      # print(w.shape)\n",
        "      return w\n",
        "  else:\n",
        "    flag = False\n",
        "    flag2 = False\n",
        "    k = mid\n",
        "\n",
        "    while True:\n",
        "      low1 = 0\n",
        "      high1 = k - 1\n",
        "\n",
        "      while low1 <= high1:\n",
        "        mid1 = (low1 + high1) // 2\n",
        "        mu = (2 * mid1 * u - torch.sum(c_sort[mid1:k]) - 2) / (k - mid1)\n",
        "\n",
        "        if mid1 != 0:\n",
        "          cond1 = torch.all((mu + c_sort[mid1] <= -2*u)).item()\n",
        "        else:\n",
        "          cond1 = True\n",
        "\n",
        "        cond2 = torch.all(((-2 * u) < (mu + c_sort[mid1]))).item() and torch.all(((mu + c_sort[k - 1]) < 0)).item()\n",
        "\n",
        "        if k < n:\n",
        "          cond3 = torch.all((mu + c_sort[k]) >= 0).item()\n",
        "        else:\n",
        "          cond3 = True\n",
        "\n",
        "        if cond1 and cond2 and cond3:\n",
        "          flag = True\n",
        "          break\n",
        "        elif cond1 and not cond2:\n",
        "          low1 = mid1 + 1\n",
        "        else:\n",
        "          high1 = mid1 - 1\n",
        "\n",
        "      if flag:\n",
        "        break\n",
        "      else:\n",
        "        k = k + 1\n",
        "\n",
        "      if k > n:\n",
        "        flag2 = True\n",
        "        break\n",
        "\n",
        "    if flag2:\n",
        "      num_elements = int(torch.ceil(torch.tensor(1/u)))\n",
        "      w[sort_indices[:num_elements]] = u\n",
        "    else:\n",
        "      w[sort_indices[:mid1]] = u\n",
        "      w[sort_indices[mid1:k]] = -(mu + c_sort[mid1:k]) / 2\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# import torch\n",
        "\n",
        "# def bisection(c, u):\n",
        "#     n = len(c)\n",
        "#     w = torch.zeros(n).reshape(503, 1)\n",
        "#     c_sort, sort_indices = torch.sort(c)\n",
        "\n",
        "#     high = n - 1\n",
        "#     low = 0\n",
        "\n",
        "#     while low <= high:\n",
        "#         mid = (low + high) // 2\n",
        "#         mu = -1/mid * (torch.sum(c_sort[:mid]) + 2)\n",
        "#         print(mu)\n",
        "\n",
        "#         tst1 = (mu + c_sort[mid - 1] < 0).item()\n",
        "#         tst2 = (mu + c_sort[mid] >= 0).item() if mid < n else True\n",
        "\n",
        "#         if tst1 and tst2:\n",
        "#             break\n",
        "#         elif tst1 and not tst2:\n",
        "#             low = mid + 1\n",
        "#         else:\n",
        "#             high = mid - 1\n",
        "\n",
        "#     if torch.all(-(mu + c_sort[:mid])/2 <= u):\n",
        "#         print(w)\n",
        "#         print(-(mu + c_sort[:mid])/2)\n",
        "#         w[sort_indices[:mid]] = -(mu + c_sort[:mid])/2\n",
        "#         print(\"Entered the if loop and this is w\")\n",
        "#         print(w)\n",
        "#         return w\n",
        "#     else:\n",
        "#         flg = False\n",
        "#         flg2 = False\n",
        "#         k = mid\n",
        "\n",
        "#         while True:\n",
        "#             low1 = 0\n",
        "#             high1 = k - 1\n",
        "\n",
        "#             while low1 <= high1:\n",
        "#                 mid1 = (low1 + high1) // 2\n",
        "#                 if k - mid1 == 0:\n",
        "#                     break\n",
        "#                 mu = (2*mid1*u - torch.sum(c_sort[mid1:k]) - 2) / (k - mid1)\n",
        "\n",
        "#                 tst1 = (mu + c_sort[mid1 - 1] <= -2*u).item() if mid1 != 0 else True\n",
        "#                 tst2 = ((-2*u) < (mu + c_sort[mid1])).item() and ((mu + c_sort[k - 1]) < 0).item()\n",
        "\n",
        "#                 tst3 = (mu + c_sort[k] >= 0).item() if k < n - 1 else True\n",
        "\n",
        "#                 if tst1 and tst2 and tst3:\n",
        "#                     flg = True\n",
        "#                     break\n",
        "#                 elif tst1 and not tst2:\n",
        "#                     low1 = mid1 + 1\n",
        "#                 else:\n",
        "#                     high1 = mid1 - 1\n",
        "\n",
        "#             if flg:\n",
        "#                 break\n",
        "#             else:\n",
        "#                 k += 1\n",
        "\n",
        "#             if k > n:\n",
        "#                 flg2 = True\n",
        "#                 break\n",
        "\n",
        "#         if flg2:\n",
        "#             num_elements = int(torch.ceil(1/u))\n",
        "#             w[sort_indices[:num_elements]] = u\n",
        "#         else:\n",
        "#             w[sort_indices[:mid1]] = u\n",
        "#             w[sort_indices[mid1:k]] = -(mu + c_sort[mid1:k])/2\n",
        "\n",
        "#         return w\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CzGeyVUHELa"
      },
      "outputs": [],
      "source": [
        "# increasing the weight\n",
        "def eteMMupdate(w, B, b, Lmax_A, reg, p , c_1, u):\n",
        "  d = reg / ((p + abs(w)) * c_1)\n",
        "  c = B @ w + 1/Lmax_A * (b + d) # calculation for q_ete, tracking error, 503 x 503 @ 503 x 1 + \n",
        "  \n",
        "  # print(f\"This is c.shape {c.shape}\")\n",
        "  c = c.reshape(503)\n",
        "  # print(f\"This is c after reshape in eteMMupdate {c.shape}\")\n",
        "\n",
        "  return bisection(c,u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnGfYsTG0-iy"
      },
      "outputs": [],
      "source": [
        "def track(data, returns, reg, thres = 1e-9, u = 1, w_0 = None, p_neg_exp = 7, max_iter = 1000):\n",
        "  X = data\n",
        "  n = X.shape[1] # assets\n",
        "  m = X.shape[0] # time\n",
        "\n",
        "  if n == 1:\n",
        "    print(\"Must track more than one asset\")\n",
        "\n",
        "  \n",
        "  w_0 = (torch.ones(n) / n).reshape(503,1) # w_0 ~ Normal\n",
        "  # print(w_0)\n",
        "  # print(f\"This is {w_0.shape}\")\n",
        "\n",
        "  F_v = torch.zeros((max_iter, 1))\n",
        "\n",
        "  K = 10\n",
        "  p_1 = 1 # initial p\n",
        "  p_k = p_neg_exp # final p\n",
        "  gamma = (p_k/p_1)**(1/K) # getting deci root\n",
        "  seq = torch.arange(0, K + 1) # sequential tensor : [0, 1, ... , k]\n",
        "  exp = gamma**seq # raising gamma to the above sequence (essentially reversing from 1 to p_k) of equiratio intervals\n",
        "  p_p = p_1 * exp\n",
        "  p_p = 10**(-p_p) # applying negative base-10 logarithmic transformation, log_10 (p_p)\n",
        "\n",
        "  p_p_div_10 = p_p/10\n",
        "  ones = 1e-3 * torch.ones_like(p_p)\n",
        "  tol = torch.min(p_p_div_10, ones) # tolerance for convergence for early stopping\n",
        "\n",
        "  k = 0 # iter tracker\n",
        "\n",
        "  # Using Empirical Tracking Error\n",
        "\n",
        "  A = 1/m * torch.transpose(X, 0, 1) @ X # building N x N matrix scaled by 1/m\n",
        "\n",
        "  eigenvalues, _ = torch.linalg.eigh(A) # calculated eigenvalue of A\n",
        "  Lmax_A = eigenvalues[-1] # retrieving maximum eigenvalue\n",
        "\n",
        "  B = 2/Lmax_A * (A - Lmax_A * torch.eye(n)) # scaled eigenvector corresponding to Lmax_A\n",
        "  b = -2/m * torch.transpose(X, 0, 1) @ returns # N x M @ M x 1 = N x 1\n",
        "\n",
        "  # => Bw_(k) + reg * d_(p,u) + b\n",
        "\n",
        "  for i in range(1,K+1):\n",
        "    p = p_p[i]\n",
        "    c_1 = torch.log(1 + u/p)\n",
        "    flag = True\n",
        "    while True:\n",
        "      k = k + 1\n",
        "      if k >= max_iter - 1:\n",
        "        break\n",
        "\n",
        "      # accelerated scheme for faster convergence (taking a double step)\n",
        "      w_1 = eteMMupdate(w_0, B, b, Lmax_A, reg, p, c_1, u)\n",
        "      w_1 = w_1.reshape(503, 1)\n",
        "      w_2 = eteMMupdate(w_1, B, b, Lmax_A, reg, p, c_1, u)\n",
        "      w_2 = w_2.reshape(503, 1)\n",
        "      R = w_1 - w_0\n",
        "      U = w_2 - w_1 - R\n",
        "      norm_R = torch.norm(R, p=2)\n",
        "      norm_U = torch.norm(U, p=2)\n",
        "\n",
        "      a = max(min(-norm_R / norm_U, -1), -300)\n",
        "\n",
        "      while True:\n",
        "        if abs(a + 1) < 1e-6:\n",
        "          w = w_2\n",
        "          F_v[k - 1] = 1/reg * torch.norm(torch.matmul(X, w) - returns)**2 + m/c_1 * torch.sum(torch.log(1 + w/p))\n",
        "          w_0 = w\n",
        "          break\n",
        "\n",
        "        w = w_0 - 2 * a * R + a**2 * U\n",
        "        w = w.reshape(503)\n",
        "        # print(f\"This is w before the bisection: {w}\")\n",
        "        w = w.reshape(503, 1)\n",
        "        w = bisection(-2 * w, u)\n",
        "        w = w.reshape(503)\n",
        "        # print(f\"This is w after the bisection: {w}\")\n",
        "        w = w.reshape(503, 1)\n",
        "        F_v[k - 1] = 1/reg * torch.norm(X @ w - returns)**2 + m/c_1 * torch.sum(torch.log(1 + w/p))\n",
        "\n",
        "        if flag == 0 and F_v[k - 1] * (1 - torch.sign(F_v[k - 1]) * 1e-9) >= F_v[max(k - 2, 0)]:\n",
        "          a = (a - 1) / 2\n",
        "        else:\n",
        "          w_0 = w\n",
        "          break\n",
        "\n",
        "      if flag == 0:\n",
        "        rel_change = torch.abs(F_v[k - 1] - F_v[k - 2]) / max(1, abs(F_v[k - 1]))\n",
        "\n",
        "        if rel_change <= tol[i] or k >= max_iter - 1:\n",
        "          break\n",
        "      flag = 0\n",
        "      \n",
        "  w[w < thres] = 0\n",
        "  w = w / sum(w)\n",
        "  return w.reshape(503)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Testing #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ticker_returns = calculateTickerReturns()\n",
        "index_returns = calculateIndexReturns()\n",
        "\n",
        "print(ticker_returns[0:5])\n",
        "print(index_returns[0:5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# bisection algorithm issues (tensor containing more than one value and being ambiguous)\n",
        "portfolio_weighting = track(ticker_returns, index_returns, reg=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tickers = []\n",
        "for i in range(len(portfolio_weighting)):\n",
        "    if portfolio_weighting[i] > 0:\n",
        "        tickers.append(curr_sp[i])\n",
        "tickers"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
