{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Params #  \n",
        "X -> m-by-n matrix of net returns (samples-by-assets)  \n",
        "r -> m-dimensional vec of net returns of index  \n",
        "reg -> sparsity regularization parameter  \n",
        "u -> upper bound of weights  \n",
        "w_0 -> initial point  \n",
        "p_neg_exp -> final negative exponent of p  \n",
        "max_iter -> max number of iterations  \n",
        "\n",
        "return n-dimensional vector w/ allocation weights on the assets  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: Add support for other indices besides S&P (maybe just simple if-else switches or passing supported index parameters)\n",
        "# TODO: Consider hw to improve sparsity in portfolio cardinality\n",
        "# TODO: Clean up debug print statements\n",
        "# TODO: Discuss potential drawbacks (if S&P performs terribly then it will be reflected, which happened in the 2022-01-01 to 2023-01-01 timeframe); Weird bug with 2023-03-01 and onwards, also with 2020-01-01, not sure what the issue is; might be smth to do with inc/exc bounds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OjzoxVJs7btS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from sec import stock, constants, lookups\n",
        "from polygon import RESTClient\n",
        "import yfinance as yf # temporary until we figure out polygon api\n",
        "import scipy\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "constants.set_polygon_key(\"_4BtZn3PRCLu6fsdu7dgddb4ucmB1sfp\")\n",
        "poly_cli = RESTClient(api_key=\"_4BtZn3PRCLu6fsdu7dgddb4ucmB1sfp\")\n",
        "torch.set_default_dtype(torch.float64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "503\n",
            "['A', 'AAL', 'AAP', 'AAPL', 'ABBV', 'ABC', 'ABT', 'ACGL', 'ACN', 'ADBE', 'ADI', 'ADM', 'ADP', 'ADSK', 'AEE', 'AEP', 'AES', 'AFL', 'AIG', 'AIZ', 'AJG', 'AKAM', 'ALB', 'ALGN', 'ALK', 'ALL', 'ALLE', 'AMAT', 'AMCR', 'AMD', 'AME', 'AMGN', 'AMP', 'AMT', 'AMZN', 'ANET', 'ANSS', 'AON', 'AOS', 'APA', 'APD', 'APH', 'APTV', 'ARE', 'ATO', 'ATVI', 'AVB', 'AVGO', 'AVY', 'AWK', 'AXON', 'AXP', 'AZO', 'BA', 'BAC', 'BALL', 'BAX', 'BBWI', 'BBY', 'BDX', 'BEN', 'BF.B', 'BG', 'BIIB', 'BIO', 'BK', 'BKNG', 'BKR', 'BLK', 'BMY', 'BR', 'BRK.B', 'BRO', 'BSX', 'BWA', 'BXP', 'C', 'CAG', 'CAH', 'CARR', 'CAT', 'CB', 'CBOE', 'CBRE', 'CCI', 'CCL', 'CDAY', 'CDNS', 'CDW', 'CE', 'CEG', 'CF', 'CFG', 'CHD', 'CHRW', 'CHTR', 'CI', 'CINF', 'CL', 'CLX', 'CMA', 'CMCSA', 'CME', 'CMG', 'CMI', 'CMS', 'CNC', 'CNP', 'COF', 'COO', 'COP', 'COST', 'CPB', 'CPRT', 'CPT', 'CRL', 'CRM', 'CSCO', 'CSGP', 'CSX', 'CTAS', 'CTLT', 'CTRA', 'CTSH', 'CTVA', 'CVS', 'CVX', 'CZR', 'D', 'DAL', 'DD', 'DE', 'DFS', 'DG', 'DGX', 'DHI', 'DHR', 'DIS', 'DLR', 'DLTR', 'DOV', 'DOW', 'DPZ', 'DRI', 'DTE', 'DUK', 'DVA', 'DVN', 'DXC', 'DXCM', 'EA', 'EBAY', 'ECL', 'ED', 'EFX', 'EG', 'EIX', 'EL', 'ELV', 'EMN', 'EMR', 'ENPH', 'EOG', 'EPAM', 'EQIX', 'EQR', 'EQT', 'ES', 'ESS', 'ETN', 'ETR', 'ETSY', 'EVRG', 'EW', 'EXC', 'EXPD', 'EXPE', 'EXR', 'F', 'FANG', 'FAST', 'FCX', 'FDS', 'FDX', 'FE', 'FFIV', 'FI', 'FICO', 'FIS', 'FITB', 'FLT', 'FMC', 'FOX', 'FOXA', 'FRT', 'FSLR', 'FTNT', 'FTV', 'GD', 'GE', 'GEHC', 'GEN', 'GILD', 'GIS', 'GL', 'GLW', 'GM', 'GNRC', 'GOOG', 'GOOGL', 'GPC', 'GPN', 'GRMN', 'GS', 'GWW', 'HAL', 'HAS', 'HBAN', 'HCA', 'HD', 'HES', 'HIG', 'HII', 'HLT', 'HOLX', 'HON', 'HPE', 'HPQ', 'HRL', 'HSIC', 'HST', 'HSY', 'HUM', 'HWM', 'IBM', 'ICE', 'IDXX', 'IEX', 'IFF', 'ILMN', 'INCY', 'INTC', 'INTU', 'INVH', 'IP', 'IPG', 'IQV', 'IR', 'IRM', 'ISRG', 'IT', 'ITW', 'IVZ', 'J', 'JBHT', 'JCI', 'JKHY', 'JNJ', 'JNPR', 'JPM', 'K', 'KDP', 'KEY', 'KEYS', 'KHC', 'KIM', 'KLAC', 'KMB', 'KMI', 'KMX', 'KO', 'KR', 'L', 'LDOS', 'LEN', 'LH', 'LHX', 'LIN', 'LKQ', 'LLY', 'LMT', 'LNC', 'LNT', 'LOW', 'LRCX', 'LUV', 'LVS', 'LW', 'LYB', 'LYV', 'MA', 'MAA', 'MAR', 'MAS', 'MCD', 'MCHP', 'MCK', 'MCO', 'MDLZ', 'MDT', 'MET', 'META', 'MGM', 'MHK', 'MKC', 'MKTX', 'MLM', 'MMC', 'MMM', 'MNST', 'MO', 'MOH', 'MOS', 'MPC', 'MPWR', 'MRK', 'MRNA', 'MRO', 'MS', 'MSCI', 'MSFT', 'MSI', 'MTB', 'MTCH', 'MTD', 'MU', 'NCLH', 'NDAQ', 'NDSN', 'NEE', 'NEM', 'NFLX', 'NI', 'NKE', 'NOC', 'NOW', 'NRG', 'NSC', 'NTAP', 'NTRS', 'NUE', 'NVDA', 'NVR', 'NWL', 'NWS', 'NWSA', 'NXPI', 'O', 'ODFL', 'OGN', 'OKE', 'OMC', 'ON', 'ORCL', 'ORLY', 'OTIS', 'OXY', 'PANW', 'PARA', 'PAYC', 'PAYX', 'PCAR', 'PCG', 'PEAK', 'PEG', 'PEP', 'PFE', 'PFG', 'PG', 'PGR', 'PH', 'PHM', 'PKG', 'PLD', 'PM', 'PNC', 'PNR', 'PNW', 'PODD', 'POOL', 'PPG', 'PPL', 'PRU', 'PSA', 'PSX', 'PTC', 'PWR', 'PXD', 'PYPL', 'QCOM', 'QRVO', 'RCL', 'REG', 'REGN', 'RF', 'RHI', 'RJF', 'RL', 'RMD', 'ROK', 'ROL', 'ROP', 'ROST', 'RSG', 'RTX', 'RVTY', 'SBAC', 'SBUX', 'SCHW', 'SEDG', 'SEE', 'SHW', 'SJM', 'SLB', 'SNA', 'SNPS', 'SO', 'SPG', 'SPGI', 'SRE', 'STE', 'STLD', 'STT', 'STX', 'STZ', 'SWK', 'SWKS', 'SYF', 'SYK', 'SYY', 'T', 'TAP', 'TDG', 'TDY', 'TECH', 'TEL', 'TER', 'TFC', 'TFX', 'TGT', 'TJX', 'TMO', 'TMUS', 'TPR', 'TRGP', 'TRMB', 'TROW', 'TRV', 'TSCO', 'TSLA', 'TSN', 'TT', 'TTWO', 'TXN', 'TXT', 'TYL', 'UAL', 'UDR', 'UHS', 'ULTA', 'UNH', 'UNP', 'UPS', 'URI', 'USB', 'V', 'VFC', 'VICI', 'VLO', 'VMC', 'VRSK', 'VRSN', 'VRTX', 'VTR', 'VTRS', 'VZ', 'WAB', 'WAT', 'WBA', 'WBD', 'WDC', 'WEC', 'WELL', 'WFC', 'WHR', 'WM', 'WMB', 'WMT', 'WRB', 'WRK', 'WST', 'WTW', 'WY', 'WYNN', 'XEL', 'XOM', 'XRAY', 'XYL', 'YUM', 'ZBH', 'ZBRA', 'ZION', 'ZTS']\n"
          ]
        }
      ],
      "source": [
        "curr_sp = lookups.get_sp500_tickers()\n",
        "print(len(curr_sp))\n",
        "print(curr_sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aggregate all close data (has been modularized below)\n",
        "# TODO: remove later after backtesting\n",
        "# close_data = torch.zeros((252, len(curr_sp)))\n",
        "\n",
        "# for i in range(len(curr_sp)):\n",
        "#     aggs = []\n",
        "#     data = poly_cli.list_aggs(ticker=curr_sp[i], multiplier=1, timespan=\"day\", from_=\"2023-02-01\", to = \"2024-02-01\")\n",
        "#     for j, agg in enumerate(data):\n",
        "#         close_data[j, i] = agg.close\n",
        "\n",
        "# print(close_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# torch.set_default_dtype(torch.float64)\n",
        "\n",
        "# col_dim = close_data.shape[0]\n",
        "# return_data = torch.zeros((252, len(curr_sp)))\n",
        "# for i in range(1, col_dim):\n",
        "#     return_data[i] = (close_data[i, :] - close_data[0, :])/close_data[0, :]\n",
        "# print(return_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 166,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @param start -> \"YYYY-MM-DD\"\n",
        "# source: https://www.tradinghours.com/publications/trading-days-per-year\n",
        "# unsure of source accuracy\n",
        "def getTradingDays(start):\n",
        "    year = start[0:4]\n",
        "\n",
        "    # hardcode trading days per year\n",
        "    tradingDays = {\n",
        "        2023: 252,\n",
        "        2022: 252,\n",
        "        2021: 252,\n",
        "        2020: 252,\n",
        "        2019: 252,\n",
        "        2018: 251,\n",
        "        2017: 251,\n",
        "        2016: 252,\n",
        "        2015: 252,\n",
        "        2014: 252,\n",
        "        2013: 252,\n",
        "        2012: 250,\n",
        "        2011: 252,\n",
        "        2010: 252\n",
        "    }\n",
        "\n",
        "    return tradingDays.get(year, 252)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @param start -> \"YYYY-MM-DD\"\n",
        "# calculates\n",
        "def getCloseData(start, period=1):\n",
        "    curr_sp = lookups.get_sp500_tickers()\n",
        "    total_days = 0\n",
        "    for i in range(period):\n",
        "        begin = str(int(start[0:4]) + i) + start[4:]\n",
        "        total_days += getTradingDays(begin)\n",
        "    close_data = torch.zeros((total_days, len(curr_sp)))\n",
        "\n",
        "    end = str(int(start[0:4]) + period) + start[4:]\n",
        "\n",
        "    for i in range(len(curr_sp)):\n",
        "        # aggs = []\n",
        "        data = poly_cli.list_aggs(ticker=curr_sp[i], multiplier=1, timespan=\"day\", from_=start, to = end)\n",
        "        for j, agg in enumerate(data):\n",
        "            # if j == total_days - 1:\n",
        "            #     break\n",
        "            close_data[j, i] = agg.close\n",
        "    return close_data\n",
        "\n",
        "# close = getCloseData(\"2023-02-01\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 186,
      "metadata": {},
      "outputs": [],
      "source": [
        "# curr_sp is current s&p tickers\n",
        "# method simply retrieves close of certain ticker we specify\n",
        "def getTickerClose(ticker, curr_sp, close_data):\n",
        "    ix = curr_sp.index(ticker)\n",
        "    print(close_data[:, ix])\n",
        "\n",
        "# getTickerClose(\"AAPL\", curr_sp, close_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 185,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculateTickerReturns(start, period=1):\n",
        "    close_data = getCloseData(start, period)\n",
        "    col_dim = close_data.shape[0]\n",
        "    # for i in range(period):\n",
        "    #     begin = str(int(start[0:4]) + i) + start[4:]\n",
        "    #     total_days += getTradingDays(begin)\n",
        "    return_data = torch.zeros((close_data.shape[0], close_data.shape[1]))\n",
        "    for i in range(1, col_dim):\n",
        "        return_data[i] = (close_data[i, :] - close_data[0, :])/close_data[0, :]\n",
        "    return return_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 184,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collectSP500(start, period=1):\n",
        "    index_symbol = \"^GSPC\"\n",
        "    end = str(int(start[0:4]) + period) + start[4:]\n",
        "    index_data = yf.download(index_symbol, start=start, end=end, interval=\"1d\")\n",
        "    index_close_data = torch.tensor(index_data[\"Close\"].values)\n",
        "    return index_close_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 183,
      "metadata": {},
      "outputs": [],
      "source": [
        "def calculateIndexReturns(start, period=1):\n",
        "    index_data = collectSP500(start, period)\n",
        "    dim = index_data.shape[0]\n",
        "    return_data = torch.zeros(dim)\n",
        "    for i in range(1, dim):\n",
        "        return_data[i] = ((index_data[i] - index_data[0])) / index_data[0]\n",
        "    return return_data.reshape(dim, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 176,
      "metadata": {},
      "outputs": [],
      "source": [
        "def preparePipeline(start, period=1):\n",
        "    ticker_returns = calculateTickerReturns(start, period)\n",
        "    index_returns = calculateIndexReturns(start, period)\n",
        "    return ticker_returns, index_returns\n",
        "# test, test2 = preparePipeline(\"2023-03d-02\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Algorithm #"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 177,
      "metadata": {
        "id": "PwnN40TU76Hy"
      },
      "outputs": [],
      "source": [
        "# funcition to solve kkt\n",
        "def bisection(c, u):\n",
        "  n = len(c)\n",
        "  w = torch.zeros(n) # new weight vector\n",
        "  c_sort, sort_indices = torch.sort(c)\n",
        "  \n",
        "  high = n - 1\n",
        "  low = 0\n",
        "\n",
        "  while low <= high:\n",
        "    mid = (low + high) // 2\n",
        "    if mid == 0:\n",
        "      break\n",
        "    mu = -1/mid * (torch.sum(c_sort[0:mid]) + 2)\n",
        "\n",
        "    cond1 = (mu + c_sort[mid] < 0).item()\n",
        "\n",
        "    if mid < n:\n",
        "      cond2 = torch.all((mu + c_sort[mid] >= 0)).item()\n",
        "    else:\n",
        "      cond2 = True\n",
        "\n",
        "    if cond1 and cond2:\n",
        "      break\n",
        "    elif cond1 and not cond2:\n",
        "      low = mid + 1\n",
        "    else:\n",
        "      high = mid - 1\n",
        "\n",
        "  new_values = -(mu + c_sort[:mid] / 2)\n",
        "  if torch.all(-(mu + c_sort[:mid])/2 <= u).item():\n",
        "      # print(f\"This is w.shape in bisection: {w.shape}\")\n",
        "      # print(f\"This is what is getting put in w in bisecttion: {(-(mu + c_sort[:mid])/2).shape}\")\n",
        "      w[sort_indices[:mid]] = -(mu + c_sort[:mid])/2\n",
        "      # print(\"We get to the if and this is executed\")\n",
        "      # print(w)\n",
        "      # print(w.shape)\n",
        "      return w\n",
        "  else:\n",
        "    flag = False\n",
        "    flag2 = False\n",
        "    k = mid\n",
        "\n",
        "    while True:\n",
        "      low1 = 0\n",
        "      high1 = k - 1\n",
        "\n",
        "      while low1 <= high1:\n",
        "        mid1 = (low1 + high1) // 2\n",
        "        mu = (2 * mid1 * u - torch.sum(c_sort[mid1:k]) - 2) / (k - mid1)\n",
        "\n",
        "        if mid1 != 0:\n",
        "          cond1 = torch.all((mu + c_sort[mid1] <= -2*u)).item()\n",
        "        else:\n",
        "          cond1 = True\n",
        "\n",
        "        cond2 = torch.all(((-2 * u) < (mu + c_sort[mid1]))).item() and torch.all(((mu + c_sort[k - 1]) < 0)).item()\n",
        "\n",
        "        if k < n:\n",
        "          cond3 = torch.all((mu + c_sort[k]) >= 0).item()\n",
        "        else:\n",
        "          cond3 = True\n",
        "\n",
        "        if cond1 and cond2 and cond3:\n",
        "          flag = True\n",
        "          break\n",
        "        elif cond1 and not cond2:\n",
        "          low1 = mid1 + 1\n",
        "        else:\n",
        "          high1 = mid1 - 1\n",
        "\n",
        "      if flag:\n",
        "        break\n",
        "      else:\n",
        "        k = k + 1\n",
        "\n",
        "      if k > n:\n",
        "        flag2 = True\n",
        "        break\n",
        "\n",
        "    if flag2:\n",
        "      num_elements = int(torch.ceil(torch.tensor(1/u)))\n",
        "      w[sort_indices[:num_elements]] = u\n",
        "    else:\n",
        "      w[sort_indices[:mid1]] = u\n",
        "      w[sort_indices[mid1:k]] = -(mu + c_sort[mid1:k]) / 2\n",
        "    # print(\"we got to this new territory\")\n",
        "    # print(f\"w in bisection: {w.shape}\")\n",
        "    return w"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 178,
      "metadata": {
        "id": "7CzGeyVUHELa"
      },
      "outputs": [],
      "source": [
        "# increasing the weight\n",
        "def eteMMupdate(w, B, b, Lmax_A, reg, p , c_1, u, m, n):\n",
        "  # print(f\"w: {w}\")\n",
        "  # print(f\"B: {B}\")\n",
        "  # print(f\"b: {b}\")\n",
        "  # print(f\"Lmax_A: {Lmax_A}\")\n",
        "  # print(f\"reg: {reg}\")\n",
        "  # print(f\"p: {p}\")\n",
        "  # print(f\"c_1: {c_1}\")\n",
        "  # print(f\"u: {u}\")\n",
        "  d = reg / ((p + abs(w)) * c_1)\n",
        "  # print(f\"d: {d}\")\n",
        "  c = B @ w + 1/Lmax_A * (b + d) # calculation for q_ete, tracking error, 503 x 503 @ 503 x 1 + \n",
        "  \n",
        "  # print(f\"This is c.shape {c.shape}\")\n",
        "  c = c.reshape(n)\n",
        "  # print(f\"This is c after reshape in eteMMupdate {c.shape}\")\n",
        "  # print(f\"c: {c}\")\n",
        "\n",
        "  return bisection(c,u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 179,
      "metadata": {
        "id": "SnGfYsTG0-iy"
      },
      "outputs": [],
      "source": [
        "def track(data, returns, reg, thres = 1e-6, u = 1, w_0 = None, p_neg_exp = 7, max_iter = 1000):\n",
        "  # error check\n",
        "  # make sure returns matrix and index vector have matching dimensions\n",
        "  if (data.shape[0] != returns.shape[0]):\n",
        "    # print(data.shape[1])\n",
        "    # print(returns.shape[0])\n",
        "    raise Exception(\"Returns matrix and index vector do not have matching dimensions! Error.\")\n",
        "\n",
        "  X = data.double()\n",
        "\n",
        "  nan_count = torch.isnan(X).sum().item()\n",
        "  # print(f\"Number of NaNs in the original matrix: {nan_count}\")\n",
        "\n",
        "  # cleaning up NaN\n",
        "  def fill_with_rolling_mean(series, window_size=10):\n",
        "    temp_series = series.copy()\n",
        "    rolling_means = temp_series.rolling(window_size, min_periods=1, center=True).mean()\n",
        "    return series.fillna(rolling_means)\n",
        "  \n",
        "  X_df = pd.DataFrame(X.numpy())\n",
        "  X_df_filled = X_df.apply(fill_with_rolling_mean, axis=1)\n",
        "  # print(X_df_filled.shape)\n",
        "\n",
        "  # nan_count = X_df_filled.isna().sum().sum()\n",
        "  # print(f\"Number of NaNs in the X_df_filled matrix: {nan_count}\")\n",
        "\n",
        "  X_df.where(pd.notna(X_df), X_df_filled, inplace=True)\n",
        "  # print(X_df.shape)\n",
        "  X = torch.tensor(X_df.to_numpy())\n",
        "  # nan_count = torch.isnan(X).sum().item()\n",
        "  # print(f\"Number of NaNs in the cleaned matrix: {nan_count}\")\n",
        "\n",
        "  n = X.shape[1] # assets\n",
        "  m = X.shape[0] # time\n",
        "\n",
        "  # if n == 1:\n",
        "  #   print(\"Must track more than one asset\")\n",
        "\n",
        "  \n",
        "  w_0 = (torch.ones(n) / n).reshape(n,1) # w_0 ~ Normal\n",
        "  # print(w_0)\n",
        "  # print(f\"This is {w_0.shape}\")\n",
        "\n",
        "  F_v = torch.zeros((max_iter, 1))\n",
        "\n",
        "  K = 10\n",
        "  p_1 = 1 # initial p\n",
        "  p_k = p_neg_exp # final p\n",
        "  gamma = (p_k/p_1)**(1/K) # getting deci root\n",
        "  seq = torch.arange(0, K + 1) # sequential tensor : [0, 1, ... , k]\n",
        "  exp = gamma**seq # raising gamma to the above sequence (essentially reversing from 1 to p_k) of equiratio intervals\n",
        "  p_p = p_1 * exp\n",
        "  p_p = 10**(-p_p) # applying negative base-10 logarithmic transformation, log_10 (p_p)\n",
        "\n",
        "  p_p_div_10 = p_p/10\n",
        "  ones = 1e-3 * torch.ones_like(p_p)\n",
        "  tol = torch.min(p_p_div_10, ones) # tolerance for convergence for early stopping\n",
        "\n",
        "  k = 0 # iter tracker\n",
        "\n",
        "  # Using Empirical Tracking Error\n",
        "\n",
        "  A = 1/m * torch.transpose(X, 0, 1) @ X # building N x N matrix scaled by 1/m\n",
        "\n",
        "  # Count NaNs\n",
        "  # nan_count = torch.isnan(A).sum().item()\n",
        "  # print(f\"Number of NaNs in the matrix: {nan_count}\")\n",
        "\n",
        "  A_numpy = A.numpy()\n",
        "  eigenvalues, _ = scipy.linalg.eigh(A_numpy)\n",
        "  # A = A.double()\n",
        "  # print(f\"A: {A}\")\n",
        "\n",
        "\n",
        "\n",
        "  # eigenvalues = torch.linalg.eigvalsh(A) # calculated eigenvalue of A\n",
        "  # print(f\"eigenvalues: {eigenvalues}\")\n",
        "  Lmax_A = np.max(eigenvalues) # retrieving maximum eigenvalue\n",
        "  # print(f\"Lmax_A: {Lmax_A}\")\n",
        "\n",
        "  B = 2/Lmax_A * (A - Lmax_A * torch.eye(n)) # scaled eigenvector corresponding to Lmax_A\n",
        "  b = -2/m * torch.transpose(X, 0, 1) @ returns # N x M @ M x 1 = N x 1\n",
        "\n",
        "  # => Bw_(k) + reg * d_(p,u) + b\n",
        "\n",
        "  for i in range(1,K+1):\n",
        "    p = p_p[i]\n",
        "    c_1 = torch.log(1 + u/p)\n",
        "    flag = True\n",
        "    while True:\n",
        "      k = k + 1\n",
        "      if k >= max_iter - 1:\n",
        "        break\n",
        "\n",
        "      # accelerated scheme for faster convergence (taking a double step)\n",
        "      w_1 = eteMMupdate(w_0, B, b, Lmax_A, reg, p, c_1, u, m, n)\n",
        "      w_1 = w_1.reshape(n, 1)\n",
        "      w_2 = eteMMupdate(w_1, B, b, Lmax_A, reg, p, c_1, u, m, n)\n",
        "      w_2 = w_2.reshape(n, 1)\n",
        "      R = w_1 - w_0\n",
        "      U = w_2 - w_1 - R\n",
        "      norm_R = torch.norm(R, p=2)\n",
        "      norm_U = torch.norm(U, p=2)\n",
        "\n",
        "      a = max(min(-norm_R / norm_U, -1), -300)\n",
        "\n",
        "      while True:\n",
        "        if abs(a + 1) < 1e-6:\n",
        "          w = w_2\n",
        "          F_v[k - 1] = 1/reg * torch.norm(torch.matmul(X, w) - returns)**2 + m/c_1 * torch.sum(torch.log(1 + w/p))\n",
        "          w_0 = w\n",
        "          break\n",
        "\n",
        "        w = w_0 - 2 * a * R + a**2 * U\n",
        "        w = w.reshape(n)\n",
        "        # print(f\"This is w before the bisection: {w}\")\n",
        "        w = w.reshape(n, 1)\n",
        "        w = bisection(-2 * w, u)\n",
        "        w = w.reshape(n)\n",
        "        # print(f\"This is w after the bisection: {w}\")\n",
        "        w = w.reshape(n, 1)\n",
        "        F_v[k - 1] = 1/reg * torch.norm(X @ w - returns)**2 + m/c_1 * torch.sum(torch.log(1 + w/p))\n",
        "\n",
        "        if flag == 0 and F_v[k - 1] * (1 - torch.sign(F_v[k - 1]) * 1e-9) >= F_v[max(k - 2, 0)]:\n",
        "          a = (a - 1) / 2\n",
        "        else:\n",
        "          w_0 = w\n",
        "          break\n",
        "\n",
        "      if flag == 0:\n",
        "        rel_change = torch.abs(F_v[k - 1] - F_v[k - 2]) / max(1, abs(F_v[k - 1]))\n",
        "\n",
        "        if rel_change <= tol[i] or k >= max_iter - 1:\n",
        "          break\n",
        "      flag = 0\n",
        "      \n",
        "  w[w < thres] = 0\n",
        "  w = w / sum(w)\n",
        "  return w.reshape(n)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 232,
      "metadata": {},
      "outputs": [],
      "source": [
        "def hdrMMupdate(w, X, r, reg, p, c_1, m, n, hub, u): #Huber downside Risk\n",
        "    d = reg / ((p + torch.abs(w)) * c_1)\n",
        "    d = d.reshape(n, 1)\n",
        "    # print(f\"d: {d}\")\n",
        "\n",
        "    # print(r.shape)\n",
        "    # print(X.shape)\n",
        "    # print(w.shape)\n",
        "\n",
        "    tmp = (r - (X @ w).reshape(m, 1)).reshape(m)\n",
        "    # print(f\"tmp: {tmp}\")\n",
        "    # print(tmp.shape)\n",
        "    alpha = torch.ones(m)\n",
        "\n",
        "    alpha[tmp > hub] = hub / tmp[tmp > hub]\n",
        "    alpha[tmp < 0] = hub / (hub - 2*tmp[tmp < 0])\n",
        "    # print(f\"alpha: {alpha}\")\n",
        "\n",
        "    q = -torch.clamp((X @ w).resize(m, 1) - r, 0)\n",
        "    # print(f\"q: {q}\")\n",
        "\n",
        "    Q = (1/m) * (X.T @ torch.diag(alpha) @ X)\n",
        "    # print(f\"Q: {Q}\")\n",
        "    eigenvalues = torch.linalg.eigvalsh(Q)\n",
        "    Lmax = max(eigenvalues)\n",
        "    # print(f\"Lmax: {Lmax}\")\n",
        "\n",
        "    # print(f\"Q: {Q.shape}\")\n",
        "    # print(f\"w: {w.shape}\")\n",
        "    # print(f\"q: {q.shape}\")\n",
        "    # print(f\"r: {r.shape}\")\n",
        "    # print(f\"d: {d.shape}\")\n",
        "    # print(\"c = (1/Lmax) * (2 * (Q - Lmax * torch.diag(torch.ones(n))) @ w + (2/m) * X.T @ torch.diag(alpha) @ (q - r) + d)\")\n",
        "    # print((X.T @ torch.diag(alpha)).shape)\n",
        "    # print((((Q - Lmax * torch.diag(torch.ones(n))) @ w).reshape(503, 1)).shape)\n",
        "    # print(((X.T @ torch.diag(alpha)) @ (q - r)).shape)\n",
        "    # print(((Q - Lmax * torch.diag(torch.ones(n))) @ w).reshape(503, 1) +  ((X.T @ torch.diag(alpha)) @ (q - r)).shape)\n",
        "\n",
        "    c = (1/Lmax) * (2 * ((Q - Lmax * torch.diag(torch.ones(n))) @ w).reshape(n, 1) + (2/m) * ((X.T @ torch.diag(alpha)) @ (q - r)) + d)\n",
        "    c = c.reshape(n)\n",
        "    # print(f\"c: {c}\")\n",
        "    \n",
        "    return bisection(c, u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 229,
      "metadata": {},
      "outputs": [],
      "source": [
        "def track_hdr(data, returns, reg=0.2, thres = 1e-6, u = 1, w_0 = None, p_neg_exp = 7, max_iter = 1000, hub = None):\n",
        "\n",
        "    if (data.shape[0] != returns.shape[0]):\n",
        "        # print(data.shape[1])\n",
        "        # print(returns.shape[0])\n",
        "        raise Exception(\"Returns matrix and index vector do not have matching dimensions! Error.\")\n",
        "\n",
        "    X = data\n",
        "\n",
        "    nan_count = torch.isnan(X).sum().item()\n",
        "    # print(f\"Number of NaNs in the original matrix: {nan_count}\")\n",
        "\n",
        "    # cleaning up NaN\n",
        "    def fill_with_rolling_mean(series, window_size=10):\n",
        "        temp_series = series.copy()\n",
        "        rolling_means = temp_series.rolling(window_size, min_periods=1, center=True).mean()\n",
        "        return series.fillna(rolling_means)\n",
        "    \n",
        "    X_df = pd.DataFrame(X.numpy())\n",
        "    X_df_filled = X_df.apply(fill_with_rolling_mean, axis=1)\n",
        "    # print(X_df_filled.shape)\n",
        "\n",
        "    # nan_count = X_df_filled.isna().sum().sum()\n",
        "    # print(f\"Number of NaNs in the X_df_filled matrix: {nan_count}\")\n",
        "\n",
        "    X_df.where(pd.notna(X_df), X_df_filled, inplace=True)\n",
        "    # print(X_df.shape)\n",
        "    X = torch.tensor(X_df.to_numpy())\n",
        "\n",
        "    X = data\n",
        "    n = X.shape[1]\n",
        "    m = X.shape[0]\n",
        "\n",
        "    w_0 = (torch.ones(n) / n).reshape(n, 1)\n",
        "\n",
        "    K = 10\n",
        "    p_1 = 1 # initial p\n",
        "    p_k = p_neg_exp # final p\n",
        "    gamma = (p_k/p_1)**(1/K) # getting deci root\n",
        "    seq = torch.arange(0, K + 1) # sequential tensor : [0, 1, ... , k]\n",
        "    exp = gamma**seq # raising gamma to the above sequence (essentially reversing from 1 to p_k) of equiratio intervals\n",
        "    p_p = p_1 * exp\n",
        "    p_p = 10**(-p_p) # applying negative base-10 logarithmic transformation, log_10 (p_p)\n",
        "\n",
        "    F_v = torch.zeros((max_iter, 1))\n",
        "\n",
        "    p_p_div_10 = p_p/10\n",
        "    ones = 1e-3 * torch.ones_like(p_p)\n",
        "    tol = torch.min(p_p_div_10, ones) # tolerance for convergence for early stopping\n",
        "\n",
        "    k = 0\n",
        "\n",
        "    # print(f\"w_0: {w_0.shape}\")\n",
        "    for i in range(1,K+1):\n",
        "        p = p_p[i]\n",
        "        c_1 = torch.log(1 + u/p)\n",
        "        flag = True\n",
        "        while True:\n",
        "            k = k + 1\n",
        "            if k >= max_iter - 1:\n",
        "                break\n",
        "\n",
        "            # accelerated scheme for faster convergence (taking a double step)\n",
        "            w_1 = hdrMMupdate(w_0, X, returns, reg, p, c_1, m, n, hub, u)\n",
        "            w_1 = w_1.reshape(n, 1)\n",
        "            w_2 = hdrMMupdate(w_1, X, returns, reg, p, c_1, m, n, hub, u)\n",
        "            w_2 = w_2.reshape(n, 1)\n",
        "            # print(f\"w_1: {w_1.shape}\")\n",
        "            # print(f\"w_2: {w_2.shape}\")\n",
        "            R = w_1 - w_0\n",
        "            # print(f\"Orig R: {R.shape}\")\n",
        "            U = w_2 - w_1 - R\n",
        "            # print(f\"Orig U: {U.shape}\")\n",
        "            norm_R = torch.norm(R, p=2)\n",
        "            norm_U = torch.norm(U, p=2)\n",
        "            a = max(min(-norm_R / norm_U, -1), -300)\n",
        "\n",
        "            while True:\n",
        "                if abs(a + 1) < 1e-6:\n",
        "                    w = w_2\n",
        "                    tmp = returns - X @ w\n",
        "                    h = torch.zeros(m)\n",
        "                    condition = torch.logical_and(tmp > 0, tmp <= hub)\n",
        "                    condition = condition.reshape(m)\n",
        "                    h[condition] = torch.pow(tmp[condition], 2).squeeze()\n",
        "                    condition = (tmp > hub)\n",
        "                    condition = condition.reshape(m)\n",
        "                    # print(condition.shape)\n",
        "                    h[condition] = (hub * (2 * torch.abs(tmp[condition]) - hub)).squeeze()\n",
        "\n",
        "                    F_v[k - 1] = (1/reg) * torch.sum(h) + (m / c_1) * torch.sum(torch.log(1 + w / p))\n",
        "                    w_0 = w\n",
        "                    break\n",
        "                # print(f\"R: {R.shape}\")\n",
        "                # print(f\"U: {U.shape}\")\n",
        "                w = w_0 - 2 * a * R + a**2 * U\n",
        "                # print(f\"w: {w.shape}\")\n",
        "\n",
        "\n",
        "                # projection\n",
        "                w = w.reshape(n, 1)\n",
        "                w = bisection(-2 * w, u)\n",
        "\n",
        "                # print(f\"w: {w}\")\n",
        "\n",
        "                w = w.reshape(n, 1)\n",
        "                tmp = returns - X @ w\n",
        "                h = torch.zeros(m)\n",
        "                condition = torch.logical_and(tmp > 0, tmp <= hub)\n",
        "                condition = condition.reshape(m)\n",
        "                h[condition] = torch.pow(tmp[condition], 2).squeeze()\n",
        "\n",
        "                F_v[k - 1] = 1/reg * torch.sum(h) + (m / c_1) * torch.sum(torch.log(1 + w / p))\n",
        "\n",
        "                if flag == 0 and F_v[k - 1] * (1 - torch.sign(F_v[k - 1]) * 1e-9) >= F_v[max(k - 2, 1)]:\n",
        "                    a = (a - 1) / 2\n",
        "                else:\n",
        "                    w_0 = w\n",
        "                    break\n",
        "\n",
        "            if flag == 0:\n",
        "                rel_change = torch.abs(F_v[k - 1] - F_v[k - 2]) / max(1, abs(F_v[k - 1]))\n",
        "\n",
        "                if rel_change <= tol[i] or k >= max_iter - 1:\n",
        "                    break\n",
        "            flag = 0\n",
        "    w[w < thres] = 0\n",
        "    w = w / torch.sum(w)\n",
        "    return w.reshape(n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experimentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 255,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[*********************100%%**********************]  1 of 1 completed\n"
          ]
        }
      ],
      "source": [
        "data, returns = preparePipeline(\"2015-01-01\", 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 257,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([252, 1])"
            ]
          },
          "execution_count": 257,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "returns.shape\n",
        "# data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "portfolio = track_hdr(data, returns, reg=0.2, u=0.5, hub=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "portfolio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 261,
      "metadata": {},
      "outputs": [],
      "source": [
        "out = []\n",
        "for i in range(len(portfolio)):\n",
        "    if portfolio[i] > 0:\n",
        "        out.append(curr_sp[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 264,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "502"
            ]
          },
          "execution_count": 264,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(out)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Backtesting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 285,
      "metadata": {},
      "outputs": [],
      "source": [
        "def run_tests(start=\"2015-01-01\", error=\"hdr\", flag=\"backtest\", train_period=1, test_period=1):\n",
        "    ticker_returns, index_returns = preparePipeline(start, train_period)\n",
        "    if error == \"hdr\":\n",
        "        portfolio_weights = track_hdr(ticker_returns, index_returns, reg=0.2, u=0.5, hub=0.05)\n",
        "    elif error == \"ete\":\n",
        "        portfolio_weights = track(ticker_returns, index_returns, reg=0.2)\n",
        "    else:\n",
        "        raise Exception(\"Invalid tracking error!\")\n",
        "\n",
        "    if flag == \"backtest\":\n",
        "        backtest_start = str(int(start[0:4]) + train_period) + start[4:] # 252 days later\n",
        "        # print(backtest_start)\n",
        "\n",
        "        # for future testing\n",
        "        ticker_returns, index_returns = preparePipeline(backtest_start, test_period)\n",
        "\n",
        "    # print(ticker_returns)\n",
        "    weights_df = pd.DataFrame(portfolio_weights.numpy())\n",
        "    returns_df = pd.DataFrame(ticker_returns.numpy())\n",
        "    index_returns_df = pd.DataFrame(index_returns.numpy())\n",
        "    # print(returns_df)\n",
        "\n",
        "    non_zero_weights = weights_df[weights_df > 0]\n",
        "    # print(non_zero_weights)\n",
        "    # print(non_zero_weights.index)\n",
        "    filtered_returns_df = returns_df.loc[:, non_zero_weights.index]\n",
        "    # print(filtered_returns_df)\n",
        "\n",
        "    weighted_returns = filtered_returns_df.mul(non_zero_weights.values.flatten(), axis=1)\n",
        "    # print(weighted_returns)\n",
        "    daily_portfolio_returns = weighted_returns.sum(axis=1)\n",
        "    # print(daily_portfolio_returns)\n",
        "\n",
        "    out = []\n",
        "    for ix, val in enumerate(portfolio_weights):\n",
        "        if val > 0:\n",
        "            out.append((curr_sp[ix], val.item()))\n",
        "\n",
        "    testing_start = str(int(start[0:4]) + train_period) + start[4:]\n",
        "\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(daily_portfolio_returns, label='Portfolio', color='blue')\n",
        "    plt.plot(index_returns_df, label=\"S&P\", color='red')\n",
        "    if flag == \"backtest\":\n",
        "        plt.title(f\"{test_period}-Year Returns since {testing_start}\")\n",
        "    else:\n",
        "        plt.title(f\"Returns over training period starting {start}\")\n",
        "    plt.xlabel('Days')\n",
        "    plt.ylabel('Cumulative Returns')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "    return out, portfolio_weights\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Backtests - 2015"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2015_5_hdr, mat_2015_5_hdr = run_tests(\"2015-01-01\", error=\"hdr\", flag=\"backtest\", train_period=1, test_period=5)\n",
        "res_2015_5_ete, mat_2015_5_ete = run_tests(\"2015-01-01\", error=\"ete\", flag=\"backtest\", train_period=1, test_period=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2015_2_hdr, mat_2015_2_hdr = run_tests(\"2015-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period = 2)\n",
        "res_2015_2_ete, mat_2015_2_ete = run_tests(\"2015-01-01\", error=\"ete\", flag=\"backtest\", train_period = 1, test_period = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2015_3_hdr, mat_2015_3_hdr = run_tests(\"2015-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period = 3)\n",
        "res_2015_3_ete, mat_2015_3_ete = run_tests(\"2015-01-01\", error=\"ete\", flag=\"backtest\", train_period = 1, test_period = 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Backtests - 2017"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2017_5_hdr, mat_2017_5_hdr = run_tests(\"2017-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period = 5)\n",
        "res_2017_5_ete, mat_2017_5_ete = run_tests(\"2017-01-01\", error=\"ete\", flag=\"backtest\", train_period = 1, test_period = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2017_2_hdr, mat_2017_2_hdr = run_tests(\"2017-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period = 2)\n",
        "res_2017_2_ete, mat_2017_2_ete = run_tests(\"2017-01-01\", error=\"ete\", flag=\"backtest\", train_period = 1, test_period = 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2017_3_hdr, mat_2017_3_hdr = run_tests(\"2017-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period = 2)\n",
        "res_2017_3_ete, mat_2017_3_ete = run_tests(\"2017-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period = 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Backtests - 2021"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2021_2_hdr, mat_2021_2_hdr = run_tests(\"2021-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period=2)\n",
        "res_2021_2_ete, mat_2021_2_ete = run_tests(\"2021-01-01\", error=\"ete\", flag=\"backtest\", train_period = 1, test_period=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Backtests-2022"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "res_2022_1_hdr, mat_2022_2_hdr = run_tests(\"2022-01-01\", error=\"hdr\", flag=\"backtest\", train_period = 1, test_period=1)\n",
        "res_2022_1_ete, mat_2022_2_ete = run_tests(\"2022-01-01\", error=\"ete\", flag=\"backtest\", train_period = 1, test_period=1)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
