{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Params #  \n",
        "X -> m-by-n matrix of net returns (samples-by-assets)  \n",
        "r -> m-dimensional vec of net returns of index  \n",
        "reg -> sparsity regularization parameter  \n",
        "u -> upper bound of weights  \n",
        "w_0 -> initial point  \n",
        "p_neg_exp -> final negative exponent of p  \n",
        "max_iter -> max number of iterations  \n",
        "\n",
        "return n-dimensional vector w/ allocation weights on the assets  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO: calculateReturns() -> transform close data into return matrix acording to param\n",
        "# TODO: Add comments to optimization algorithm along with mathematical formulation (Henry)\n",
        "# TODO: modularize pipeline\n",
        "# TODO: Look into HUBER tracking error algo (potentially many others to consider although might be a good idea to survey those with most potential)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OjzoxVJs7btS"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import math\n",
        "from sec import stock, constants, lookups\n",
        "from polygon import RESTClient"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "constants.set_polygon_key(\"_4BtZn3PRCLu6fsdu7dgddb4ucmB1sfp\")\n",
        "poly_cli = RESTClient(api_key=\"_4BtZn3PRCLu6fsdu7dgddb4ucmB1sfp\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "curr_sp = lookups.get_sp500_tickers()\n",
        "print(len(curr_sp))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(curr_sp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# aggregate all data\n",
        "close_data = torch.zeros((252, len(curr_sp)))\n",
        "\n",
        "for i in range(len(curr_sp)):\n",
        "    aggs = []\n",
        "    data = poly_cli.list_aggs(ticker=curr_sp[i], multiplier=1, timespan=\"day\", from_=\"2023-02-01\", to = \"2024-02-01\")\n",
        "    for j, agg in enumerate(data):\n",
        "        close_data[j, i] = agg.close\n",
        "\n",
        "print(close_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def getTickerClose(ticker, curr_sp, close_data):\n",
        "    ix = curr_sp.index(ticker)\n",
        "    print(close_data[:, ix])\n",
        "\n",
        "getTickerClose(\"AAPL\", curr_sp, close_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PwnN40TU76Hy"
      },
      "outputs": [],
      "source": [
        "def bisection(c, u):\n",
        "  n = len(c)\n",
        "  w = torch.zeros(n)\n",
        "\n",
        "  c_sort, sort_ind = torch.sort(c)\n",
        "\n",
        "  high = n\n",
        "  low = 1\n",
        "\n",
        "  while low <= high:\n",
        "    mid = (low + high) // 2\n",
        "    mu = -1/mid * (torch.sum(c_sort[0:mid]) + 2) if mid != 0 else float('-inf')\n",
        "\n",
        "    cond1 = (mu + c_sort[mid]) < 0\n",
        "    if mid < n:\n",
        "      cond2 = (mu + c_sort[mid + 1] >= 0)\n",
        "    else:\n",
        "      cond2 = True\n",
        "\n",
        "    if cond1 and cond2:\n",
        "      break\n",
        "    elif cond1 and not cond2:\n",
        "      low = mid + 1\n",
        "    else:\n",
        "      high = mid - 1\n",
        "\n",
        "  new_values = -(mu + c_sort[:mid]) / 2\n",
        "  if torch.max(new_values) <= u:\n",
        "    w[sort_ind[:mid]] = new_values\n",
        "    return w\n",
        "  else:\n",
        "    flag = False\n",
        "    flag2 = False\n",
        "    k = mid\n",
        "\n",
        "    while True:\n",
        "      low1 = 0\n",
        "      high1 = k - 1\n",
        "\n",
        "      while low1 <= high1:\n",
        "        mid1 = (low1 + high1) // 2\n",
        "        if mid1 < k - 1:\n",
        "          mu = (2 * mid1 * u - torch.sum(c_sort[mid1:k]) - 2) / (k - mid1)\n",
        "        else:\n",
        "          mu = float('-inf')\n",
        "\n",
        "        if mid1 != 0:\n",
        "          cond1 = mu + c_sort[mid1] <= -2*u\n",
        "        else:\n",
        "          cond2 = True\n",
        "\n",
        "        cond2 = ((-2 * u) < (mu + c_sort[mid1 + 1])) and ((mu + c_sort[k]) < 0)\n",
        "\n",
        "        if k < n:\n",
        "          cond3 = (mu + c_sort[k+1]) >= 0\n",
        "        else:\n",
        "          cond3 = True\n",
        "\n",
        "        if cond1 and cond2 and cond3:\n",
        "          flag = True\n",
        "          break\n",
        "        elif cond1 and not cond2:\n",
        "          low1 = mid1 + 1\n",
        "        else:\n",
        "          high1 = mid1 - 1\n",
        "\n",
        "      if flag:\n",
        "        break\n",
        "      else:\n",
        "        k = k + 1\n",
        "\n",
        "      if k > n:\n",
        "        flag2 = True\n",
        "        break\n",
        "\n",
        "      if flag2:\n",
        "        num_elements = int(torch.ceil(torch.tensor(1/u).item()))\n",
        "        w[sort_ind[num_elements]] = u\n",
        "      else:\n",
        "        w[sort_ind[:mid1]] = u\n",
        "        w[sort_ind[mid1:k]] = -(mu + c_sort[mid1:k]) / 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CzGeyVUHELa"
      },
      "outputs": [],
      "source": [
        "def eteMMupdate(w, B, b, Lmax_A, reg, p , c_1, u):\n",
        "  d = reg / ((p + abs(w)) * c_1)\n",
        "  c = B @ w + 1/Lmax_A * (b + d)\n",
        "\n",
        "  return bisection(c,u)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SnGfYsTG0-iy"
      },
      "outputs": [],
      "source": [
        "def track(self, data, returns, reg, u = 1, w_0 = None, p_neg_exp = 7, max_iter = 1000):\n",
        "  X = data\n",
        "  n = X.shape[0]\n",
        "  m = X.shape[1]\n",
        "\n",
        "  if n == 1:\n",
        "    print(\"Must track more than one asset\")\n",
        "\n",
        "  if not w_0: # w_0 = None -> Normal Distribution\n",
        "    w_0 = torch.ones(n) / n\n",
        "\n",
        "  F_v = torch.zeros((max_iter, 1))\n",
        "\n",
        "  K = 10\n",
        "  p_1 = 1\n",
        "  p_k = p_neg_exp\n",
        "  gamma = (p_k/p_1)**(1/K)\n",
        "  seq = torch.arange(0, K + 1)\n",
        "  exp = gamma**seq\n",
        "  p_p = p_1 * exp\n",
        "  p_p = 10**(-p_p)\n",
        "\n",
        "  p_p_div_10 = p_p/10\n",
        "  ones = 1e-3 * torch.ones_like(p_p)\n",
        "  tol = torch.min(p_p_div_10, ones)\n",
        "\n",
        "  k = 0 # iter tracker\n",
        "\n",
        "  # Using Empirical Tracking Error\n",
        "\n",
        "  A = 1/m * torch.transpose(X) @ X\n",
        "\n",
        "  eigenvalues, _ = torch.linalg.eigh(A)\n",
        "  Lmax_A = eigenvalues[-1]\n",
        "\n",
        "  B = 2/Lmax_A * (A - Lmax_A * torch.eye(n))\n",
        "  b = -2/m * torch.transpose(X) @ returns\n",
        "\n",
        "  for i in range(1,K+1):\n",
        "    p = p_p[i]\n",
        "    c_1 = torch.log(1 + u/p)\n",
        "    flag = True\n",
        "\n",
        "    while True:\n",
        "      k = k = 1\n",
        "\n",
        "      w_1 = eteMMupdate(w_0, B, b, Lmax_A, reg, p, c_1, u)\n",
        "      w_2 = eteMMupdate(w_1, B, b, Lmax_A, reg, p, c_1, u)\n",
        "      R = w_1 - w_0\n",
        "      U = w_2 - w_1 - R\n",
        "      norm_R = torch.norm(R)\n",
        "      norm_U = torch.norm(U)\n",
        "\n",
        "      a = max(min(-norm_R / norm_U, -1), -300)\n",
        "\n",
        "      while True:\n",
        "        if torch.abs(a + 1) < 1e-6:\n",
        "          w = w_2\n",
        "          F_v[k] = 1/reg * torch.norm(torch.matmul(X, w) - returns)**2 + m/c_1 * torch.sum(torch.log(1 + w/p))\n",
        "          w_0 = w\n",
        "          break\n",
        "\n",
        "        w = w_0 - 2 * a * R + a**2 * U\n",
        "\n",
        "        w = bisection(-2 * w, u)\n",
        "        F_v[k] = 1/reg * torch.norm(torch.matmul(X, w) - returns)**2 + m/c_1 * torch.sum(torch.log(1 + w/p))\n",
        "\n",
        "        if flag == 0 and F_v[k] * (1 - torch.sign(F_v[k]) * 1e-9) >= F_v[max(k - 1, 0)]:\n",
        "          a = (a - 1) / 2\n",
        "        else:\n",
        "          w_0 = w\n",
        "          break\n",
        "\n",
        "      if flag == 0:\n",
        "        rel_change = torch.abs(F_v[k] - F_v[k - 1]) / max(1, torch.abs(F_v[k - 1]))\n",
        "\n",
        "        if rel_change <= tol[i] or k >= max_iter:\n",
        "          break\n",
        "      flag = 0\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
